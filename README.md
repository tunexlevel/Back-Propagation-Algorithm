# Back-Propagation-Algorithm
This is an algorithm that implements BPA for a multiple layer neural network
w   = stands for the weight of the network. Each element is made of the value,head and tail. That is, head is the input layer of the weight while tail is the output layer
y   = the hidden layers
z   = the output layers
t   = target value
b   = baises
n   = hearter value
